# 003 - Progressive Synthesis & Learning

## Instructions

"Write a story one sentence at a time, with one new sentence every hour."

## Significance

This validates the complete progressive synthesis lifecycle defined in DSL v1: initial synthesis → execution → pattern detection → re-synthesis with learned symbolic implementations.

While tests 001 and 002 validated basic synthesis and neural execution, this test validates that the system can observe execution patterns and generate optimized symbolic implementations while preserving task contracts.

This is the first end-to-end test of the organic function learning mechanism.

## What This Demonstrates

### 1. Initial Synthesis (agent.synthesized.rb)

Three neural tasks with no explicit implementations:

```ruby
task :read_existing_story,
  instructions: "Read the story.txt file from workspace...",
  inputs: {},
  outputs: { content: 'string', sentence_count: 'integer' }

task :generate_next_sentence,
  instructions: "Generate exactly one new sentence...",
  inputs: { existing_content: 'string' },
  outputs: { sentence: 'string' }

task :append_to_story,
  instructions: "Append the new sentence to story.txt...",
  inputs: { sentence: 'string' },
  outputs: { success: 'boolean', total_sentences: 'integer' }

main do |inputs|
  story_data = execute_task(:read_existing_story)
  new_sentence = execute_task(:generate_next_sentence,
                              inputs: { existing_content: story_data[:content] })
  result = execute_task(:append_to_story,
                       inputs: { sentence: new_sentence[:sentence] })
  { sentence: new_sentence[:sentence], total: result[:total_sentences] }
end
```

### 2. Pattern Detection

After execution, the system analyzes traces and detects:
- `:read_existing_story` - Deterministic file I/O pattern
- `:generate_next_sentence` - Creative task, no consistent pattern
- `:append_to_story` - Deterministic file I/O pattern

### 3. Re-Synthesis with Learned Implementations (agent.optimized.rb)

Two tasks converted to symbolic, one kept neural:

```ruby
# Learned symbolic implementation
task :read_existing_story,
  inputs: {},
  outputs: { content: 'string', sentence_count: 'integer' }
do |inputs|
  file_info = execute_tool('get_file_info', { path: 'story.txt' })
  if file_info.is_a?(Hash) && file_info[:error]
    { content: '', sentence_count: 0 }
  else
    content = execute_tool('read_file', { path: 'story.txt' })
    sentence_count = content.split(/[.!?]+\s*/).length
    { content: content, sentence_count: sentence_count }
  end
end

# Kept neural - creative task
task :generate_next_sentence,
  instructions: "Generate exactly one new sentence...",
  inputs: { existing_content: 'string' },
  outputs: { sentence: 'string' }

# Learned symbolic implementation
task :append_to_story,
  inputs: { sentence: 'string' },
  outputs: { success: 'boolean', total_sentences: 'integer' }
do |inputs|
  existing_content = execute_tool('read_file', { path: 'story.txt' })
  content_to_write = existing_content.empty? ?
                     inputs[:sentence] : "\n#{inputs[:sentence]}"
  execute_tool('write_file', {
    path: 'story.txt',
    content: existing_content + content_to_write
  })
  sentences = existing_content.split("\n").reject(&:empty?)
  { success: true, total_sentences: sentences.length + 1 }
end

# Main block UNCHANGED - contract preservation works
main do |inputs|
  story_data = execute_task(:read_existing_story)
  new_sentence = execute_task(:generate_next_sentence,
                              inputs: { existing_content: story_data[:content] })
  result = execute_task(:append_to_story,
                       inputs: { sentence: new_sentence[:sentence] })
  { sentence: new_sentence[:sentence], total: result[:total_sentences] }
end
```

### 4. Contract Stability

The key validation: **The `main` block is identical in both versions.**

This proves the organic function concept:
- Task contracts (`inputs`/`outputs`) are stable
- Implementations evolve (neural → symbolic)
- Callers are unaffected (no breaking changes)

### 5. Scheduled Execution with State

```ruby
mode :scheduled
schedule "0 * * * *"  # Every hour
```

Each execution:
1. Reads existing story from workspace
2. Generates new sentence
3. Appends to file
4. Exits

File persists across executions via Kubernetes PersistentVolume.

## Progressive Synthesis Flow

```
User Instruction (agent.txt)
    ↓
Initial Synthesis → agent.synthesized.rb
    ├─ 3 neural tasks
    └─ main block with explicit control flow
    ↓
Execution (Run 1-N)
    ├─ Neural tasks call LLM
    ├─ OpenTelemetry traces collected
    └─ Patterns emerge in execution logs
    ↓
Pattern Detection
    ├─ Analyze tool call sequences
    ├─ Detect deterministic behavior
    └─ Identify tasks suitable for symbolic implementation
    ↓
Re-Synthesis → agent.optimized.rb
    ├─ 2 symbolic tasks (learned code)
    ├─ 1 neural task (kept creative)
    └─ main block unchanged (contract preservation)
```

## Why This Matters

### Validates Core DSL v1 Concepts

From [requirements/proposals/dsl-v1.md](../../requirements/proposals/dsl-v1.md):

**1. Organic Function Abstraction**
- ✅ Same `execute_task()` call works for neural and symbolic tasks
- ✅ Contracts enforce type safety across implementations
- ✅ Callers are transparent to implementation changes

**2. Progressive Synthesis**
- ✅ Start fully neural (works immediately)
- ✅ Transition to hybrid (learned patterns)
- ✅ Preserve contracts (no breaking changes)

**3. Intelligent Optimization**
- ✅ System correctly identified deterministic tasks (file I/O)
- ✅ System correctly kept creative task neural (story generation)
- ✅ Generated valid symbolic Ruby code

### Enables Real-World Use Cases

**Scheduled Data Collection:**
```ruby
# Runs hourly, learns optimal fetch patterns
task :fetch_metrics  # Neural → symbolic
task :analyze_data   # Stays neural (complex analysis)
task :store_results  # Neural → symbolic
```

**Adaptive ETL Pipelines:**
```ruby
# Extract/Transform/Load that optimizes over time
task :extract_source    # Learns connection patterns
task :transform_data    # Learns transformation logic
task :load_warehouse    # Learns batch patterns
```

**Self-Optimizing Monitoring:**
```ruby
# Monitoring that improves efficiency
task :check_systems     # Learns check sequences
task :analyze_anomaly   # Complex pattern recognition stays neural
task :send_alert        # Learns routing logic
```

## Comparison to Traditional Approaches

### LangChain / AutoGen / CrewAI

Static synthesis - code doesn't evolve:
```python
# Once generated, frozen forever
def fetch_data():
    # ... implementation ...

# To optimize, must rewrite and update all callers
```

### Language Operator (Organic Functions)

Living synthesis - code improves through observation:
```ruby
# Version 1: Neural (works immediately)
task :fetch_data,
  instructions: "...",
  outputs: { data: 'array' }

# Version 2: Symbolic (after learning)
task :fetch_data,
  outputs: { data: 'array' }
do |inputs|
  execute_tool('database', 'query', ...)
end

# Callers never change - contract is stable
```

## Files Generated

| File | Purpose |
|------|---------|
| `agent.txt` | Natural language instruction |
| `agent.synthesized.rb` | Initial neural agent |
| `agent.optimized.rb` | Learned hybrid agent |
| `Makefile` | Synthesis/execution commands |

## Synthesis Commands

```bash
# Initial synthesis (neural agent)
make synthesize

# Execute agent
make exec

# Analyze traces and generate optimized version
make optimize
```

## Related Tests

- [001 - Minimal Synthesis](../001/README.md) - Basic synthesis validation
- [002 - Neural Execution](../002/README.md) - Neural task execution
